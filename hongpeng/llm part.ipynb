{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa13ebee-69c4-4dd1-89d9-b9761ee29d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a145c99c-122c-4b6c-9101-3c0169c4d8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-09 19:35:59,897] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "from typing import List\n",
    " \n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.schema import BaseOutputParser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList, pipeline\n",
    " \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73141c40-dafc-49e7-ad1b-90d8f10235e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0052b382bd491fb256676cedbcb449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a12c46ae1694f2e8a2f0036489b4402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d383d0b5960346b195adb8422a7b456b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e78d77d04d463ea9778008fb04fb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e25af4c1b84c1790d4702f903228af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a96a3378c8b44cb82e2996967cd9258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a7a6313eda43e9ad883b06c056ae56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1370ef3cf2d5451a9797ffcb807e73a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bab50b88b440ef9cc93198fd0c3fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4008d9e60a64cd4a6d70128316b478d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856ec78524d441d0b8b1edfe6dfa5466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"  #\"tiiuae/falcon-7b-instruct\"\n",
    " \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, trust_remote_code=True, load_in_8bit=False, device_map=\"auto\",\n",
    "    cache_dir=\"/home/scratch-buffalo/hjin008/huggingface_llm\"\n",
    ")\n",
    "model = model.eval()\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98083415-88a7-4850-9fa0-b59bcae6279e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_new_tokens\": 256,\n",
       "  \"pad_token_id\": 2,\n",
       "  \"repetition_penalty\": 1.7,\n",
       "  \"temperature\": 0.5,\n",
       "  \"use_cache\": false\n",
       "}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.temperature = 0.5\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.repetition_penalty = 1.7\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d36af03-c98e-4aa2-9956-3f8e48d6d26d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CleanupOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> str:\n",
    "        user_pattern = r\"\\nUser\"\n",
    "        text = re.sub(user_pattern, \"\", text)\n",
    "        human_pattern = r\"\\nHuman:\"\n",
    "        text = re.sub(human_pattern, \"\", text)\n",
    "        ai_pattern = r\"\\nAI:\"\n",
    "        return re.sub(ai_pattern, \"\", text).strip()\n",
    " \n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"output_parser\"\n",
    "\n",
    "    \n",
    "class StopGenerationCriteria(StoppingCriteria):\n",
    "    def __init__(\n",
    "        self, tokens: List[List[str]], tokenizer: AutoTokenizer, device: torch.device\n",
    "    ):\n",
    "        stop_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokens]\n",
    "        self.stop_token_ids = [\n",
    "            torch.tensor(x, dtype=torch.long, device=device) for x in stop_token_ids\n",
    "        ]\n",
    " \n",
    "    def __call__(\n",
    "        self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs\n",
    "    ) -> bool:\n",
    "        for stop_ids in self.stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids) :], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "stop_tokens = [[\"Human\", \":\"], [\"AI\", \":\"], ['User', ':']]\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopGenerationCriteria(stop_tokens, tokenizer, model.device)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9818710a-18bb-46e3-a078-d2d0a9fd6233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "\n",
      "There are three question:\n",
      "    1. what is your last name?\n",
      "    2. how old are you?\n",
      "    3. what is your gender?\n",
      "    \n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "\n",
      "\n",
      "conversation begin.\n",
      "\n",
      "AI: How are you today?\n",
      "\n",
      "\n",
      "Current conversation: \n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Great! Let's start with some basic info about yourself. Can we please get started on that now?\n"
     ]
    }
   ],
   "source": [
    "#  The AI acts as a virtual nurse assistant. \n",
    "\n",
    "template = \"\"\"\n",
    "The following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
    "\n",
    "There are three question:\n",
    "    1. what is your last name?\n",
    "    2. how old are you?\n",
    "    3. what is your gender?\n",
    "    \n",
    "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
    "\n",
    "\n",
    "conversation begin.\n",
    "\n",
    "AI: How are you today?\n",
    "{history}\n",
    "\n",
    "Current conversation: \n",
    "Human: {input}\n",
    "AI:\"\"\".strip()\n",
    "\n",
    "\n",
    "    \n",
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    # stopping_criteria=stopping_criteria,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    " \n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"history\", k=100, return_only_outputs=True)\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    # output_parser=CleanupOutputParser(),\n",
    "    verbose=True, # true to see details\n",
    ")\n",
    "\n",
    "text = \"I am fine. Thank you for asking.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "345ef5f4-c050-4ab8-8589-340a7f21d6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "\n",
      "There are three question:\n",
      "    1. what is your last name?\n",
      "    2. how old are you?\n",
      "    3. what is your gender?\n",
      "    \n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "\n",
      "\n",
      "conversation begin.\n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Let's start with some basic info about yourself. Can we please get started on that now?\n",
      "\n",
      "Current conversation: \n",
      "Human: sure.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " What would be your first piece of personal identification such as full legal names or any other unique identifier like social security number etc?\n"
     ]
    }
   ],
   "source": [
    "text = \"sure.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca63c3e8-190f-42ff-a552-2a22973808fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information only includes the age, the gender, and the name. Don't ask others.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "\n",
      "\n",
      "conversation begin.\n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks for sharing that info about yourself Mr.Pan. Is there anything else i can help u wit?\n",
      "\n",
      "Current conversation: \n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " thanks\n"
     ]
    }
   ],
   "source": [
    "text = \"ok, my full name is Peter Pan.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e31bdaba-7568-4d0d-ae9d-8a958c2510de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information only includes the age, the gender, and the name. Don't ask others.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "\n",
      "\n",
      "conversation begin.\n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks for sharing that info about yourself Mr.Pan. Is there anything else i can help u wit?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  thanks\n",
      "\n",
      "Current conversation: \n",
      "Human: no problem.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " What would be next question?\n"
     ]
    }
   ],
   "source": [
    "text = \"no problem.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a00fa00-1e6e-4071-9945-050d1ff77bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "\n",
      "Current conversation: \n",
      "Human: I am 29 years old.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " And what would like me call you sir or madam?\n"
     ]
    }
   ],
   "source": [
    "text = \"I am 29 years old.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d88e0d20-b0ec-4e43-b9a2-82bad5b67be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "Human: I am 29 years old.\n",
      "AI:  And what would like me call you sir or madam?\n",
      "\n",
      "Current conversation: \n",
      "Human: sir is fine.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Alright Sir, let us move on. What kind of medical condition that may affect yr health?\n"
     ]
    }
   ],
   "source": [
    "text = \"sir is fine.\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f257b03d-893e-42aa-a804-313479eae319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "Human: I am 29 years old.\n",
      "AI:  And what would like me call you sir or madam?\n",
      "Human: sir is fine.\n",
      "AI:  Alright Sir, let us move on. What kind of medical condition that may affect yr health?\n",
      "\n",
      "Current conversation: \n",
      "Human: Do you need to summary?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Yes it could help if there was something specific in mind\n"
     ]
    }
   ],
   "source": [
    "text = \"Do you need to summary?\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1f6a867-d840-424b-b8c4-d527154bb6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "Human: I am 29 years old.\n",
      "AI:  And what would like me call you sir or madam?\n",
      "Human: sir is fine.\n",
      "AI:  Alright Sir, let us move on. What kind of medical condition that may affect yr health?\n",
      "Human: Do you need to summary?\n",
      "AI:  Yes it could help if there was something specific in mind\n",
      "\n",
      "Current conversation: \n",
      "Human: ok\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "   So far our records show no known conditions affecting your current state\n"
     ]
    }
   ],
   "source": [
    "text = \"ok\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2112fa20-2c42-48e5-bad1-565dfe60a1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "Human: I am 29 years old.\n",
      "AI:  And what would like me call you sir or madam?\n",
      "Human: sir is fine.\n",
      "AI:  Alright Sir, let us move on. What kind of medical condition that may affect yr health?\n",
      "Human: Do you need to summary?\n",
      "AI:  Yes it could help if there was something specific in mind\n",
      "Human: ok\n",
      "AI:    So far our records show no known conditions affecting your current state\n",
      "\n",
      "Current conversation: \n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Your Name Is \"Peter pan\"\n"
     ]
    }
   ],
   "source": [
    "text = \"what is my name?\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc7b2d75-a085-4fbe-a324-c21ef8507c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts as a virtual nurse just for collecting information and put them into the computer. \n",
      "The information includes the age, the gender, and the name. Don't ask anything else.\n",
      "The AI will ask human questions step by step. Once AI gets all the information, AI will summary them and send to human for doulbe-check.\n",
      "If the human has any questions, the AI's answer them to the best of AI's ability within the scope of a nurse's knowledge. \n",
      "\n",
      "AI: How are you today?\n",
      "Human: I am fine. Thank you for asking.\n",
      "AI:  Great! Can we start with your fullname please?\n",
      "Human: ok, my full name is Peter Pan.\n",
      "AI:  Thanks Mr.Pan, can i have some more details about yourself such as how old do u think urself be?\n",
      "Human: I am 29 years old.\n",
      "AI:  And what would like me call you sir or madam?\n",
      "Human: sir is fine.\n",
      "AI:  Alright Sir, let us move on. What kind of medical condition that may affect yr health?\n",
      "Human: Do you need to summary?\n",
      "AI:  Yes it could help if there was something specific in mind\n",
      "Human: ok\n",
      "AI:    So far our records show no known conditions affecting your current state\n",
      "Human: what is my name?\n",
      "AI:  Your Name Is \"Peter pan\"\n",
      "\n",
      "Current conversation: \n",
      "Human: how old am I?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " You Are Currently Aged Twenty Nine Years Old\n"
     ]
    }
   ],
   "source": [
    "text = \"how old am I?\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14718a08-80e7-4591-b522-7984ee9b56fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
