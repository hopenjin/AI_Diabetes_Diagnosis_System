{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8a72b1-6b65-405c-b4a6-e7b641f7191d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-12 19:26:05,503] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0122b4b552429599b2bc4cc6679b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,7\"\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed\n",
    "set_seed(42)\n",
    "\n",
    "MODEL_NAME = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True, load_in_8bit=False, \n",
    "                                             device_map=\"auto\", cache_dir=\"/home/scratch-buffalo/hjin008/huggingface_llm\")\n",
    "model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "tokenizer.sep_token = tokenizer.unk_token\n",
    "tokenizer.cls_token = tokenizer.unk_token\n",
    "tokenizer.mask_token = tokenizer.unk_token\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-beta\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, torch_dtype=torch.bfloat16, device_map=\"auto\",)\n",
    "\n",
    "\n",
    "def text2json_trans(txt):\n",
    "    # messages = [{\"role\": \"system\",\"content\": \"Your are a smart junior programmer.\"},\n",
    "    #             {\"role\": \"user\", \"content\": f'''Please summarize the following text related personal information as a json which only includes name, age, gender, and BMI: {txt}'''}]\n",
    "    # prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    # outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "    # # print(outputs[0][\"generated_text\"])\n",
    "    # # print('--'*60)\n",
    "    # text = outputs[0][\"generated_text\"]\n",
    "    # start = text.find(\"{\")\n",
    "    # end = text.find(\"}\", start) + 1\n",
    "    # json_text = text[start:end]\n",
    "    # json_data = json.loads(json_text)\n",
    "    # # print(json_text)\n",
    "    # return json_data\n",
    "    import json\n",
    "    import re\n",
    "    messages = [{\"role\": \"system\",\"content\": \"Your are a smart junior programmer.\"},\n",
    "                {\"role\": \"user\", \"content\": f'''Please summarize the following text related personal information as a json.\n",
    "                the json which only includes name, age, BMI, GenHlth(general health, scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor), \n",
    "                HighBP(0 = no, 1 = yes), DiffWalk(0 = no, 1 = yes), HighChol(0 = no, 1 = yes), and HeartDiseaseorAttack(0 = no, 1 = yes): {txt}'''}]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True)\n",
    "    # print(outputs[0][\"generated_text\"])\n",
    "    # print('--'*60)\n",
    "    text = outputs[0][\"generated_text\"]\n",
    "    start = text.find(\"{\")\n",
    "    end = text.find(\"}\", start) + 1\n",
    "    json_text = text[start:end]\n",
    "    json_text = re.sub(r'(?<!\\\\\")//.*', '', json_text)\n",
    "    json_data = json.loads(json_text)\n",
    "    # print(json_text)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def generate_response(user_input):\n",
    "    # add the user's reponse to the chat records\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # transfer messages list by the chat template for llm better understanding and generating\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # llm generating response\n",
    "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "\n",
    "    # get the llm response\n",
    "    generated_text = outputs[0][\"generated_text\"]\n",
    "    assistant_response = generated_text[len(prompt):].strip()\n",
    "\n",
    "    # add the AI assistant's response to the chat records\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "    return assistant_response\n",
    "\n",
    "\n",
    "# remove some non-literal part to make the chat records clean\n",
    "def post_process(text):\n",
    "    for icon in ['<|>','\\n', \"<|assistant|>\"]:\n",
    "        text = text.replace(icon, \"\").strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed895cc5-9077-49ca-9985-9ec9ecbb24ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello! How may I assist you today? Please allow me to introduce myself. My name is NurseBot, and I'm here to help you with any health-related questions you may have. What is your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  peter jack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello, Peter Jack. Can you please tell me your age?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Thank you, Peter Jack. Can you tell me your height and weight, please? Let's calculate your Body Mass Index (BMI) for you.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  I know my BMI, it's 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Great, Peter Jack. Can you tell me your general health status, or GenHlth? Do you have any ongoing medical conditions?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  should very good. No medication currently.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: That's excellent to hear, Peter Jack. Do you have a history of high blood pressure, or HighBP?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Have you ever had any difficulty walking, or DiffWalk? Do you experience any weakness or numbness in your legs?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Do you have a history of high cholesterol, or HighChol? Have you been diagnosed with high cholesterol, or are you currently being treated for it?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Have you ever been diagnosed with heart disease or heart attack, or HeartDiseaseorAttack? If so, please provide me with more details about your condition.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Thank you for providing me with all of this information, Peter Jack. Can you please confirm that the information I have is correct? Is there anything else you would like to add or clarify?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  could you summarize them for me to confirm?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Certainly, Peter Jack. Let me summarize the information you provided for you:- Name: Peter Jack- Age: 21- BMI: 24- GenHlth: Good, no ongoing medical conditions- HighBP: No- DiffWalk: No- HighChol: No- HeartDiseaseorAttack: NoIs this information correct? Please let me know if you have any other details you would like to add or clarify.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "user:  that is right.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Peter Jack', 'age': 21, 'gender': None, 'bmi': 24}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system information and initail chat recode\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a professional nurse.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": '''The following is a conversation between a assistant an user. As a hospital nurse, the assistant is engaging in a conversation with the user to inquire about some information including user's name, age, BMI, GenHlth(general health), HighBP, DiffWalk, HighChol, and HeartDiseaseorAttack. \n",
    "The conversation should be conducted in a dialogue format, with each question asked individually. The interaction should be characterized by a friendly and patient demeanor. \n",
    "The conversation will begin with a greeting from assistant, followed by the questions. Rememble ask one question a time.\n",
    "After all the questions have been asked, assistant will summarize the information gathered and confirm its accuracy with user. Ok, take a deep breath, and let's go!'''},\n",
    "]\n",
    "\n",
    "# runing the chat function\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    if \"that is right.\" in user_input.lower(): break\n",
    "    response = generate_response(user_input)\n",
    "    response = post_process(response)\n",
    "    print(\"assistant:\", response)\n",
    "\n",
    "# change the summary information to JSON\n",
    "res = text2json_trans(messages[-1]['content'].replace('<|assistant|>',' ').replace('\\n',' '))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a526b56-ff18-4c17-8a33-ad540f544372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please summarize the following text related personal information as a json.             the json which only includes name, age, BMI, GenHlth(general health, scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor),              HighBP(0 = no, 1 = yes), DiffWalk(0 = no, 1 = yes), HighChol(0 = no, 1 = yes), and HeartDiseaseorAttack(0 = no, 1 = yes):         <|> Certainly! Based on the information you've provided, your name is Peter Jack, you're a 9-year-old female, your height is 170 centimeters, your weight is 49 kilograms, your BMI is [BMI calculated], you're a vegetarian, your annual income is 30,000, and you don't have any medical conditions or recent surgeries or procedures to report. Is that correct?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = messages[-1]['content'].replace('<|assistant|>',' ').replace('\\n',' ')\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04295d4c-7e87-4af4-9ab7-b71ec798ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Your are a smart junior programmer.</s>\n",
      "<|user|>\n",
      "Please summarize the following text related personal information as a json.\n",
      "            the json which only includes name, age, BMI, GenHlth(general health, scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor), \n",
      "            HighBP(0 = no, 1 = yes), DiffWalk(0 = no, 1 = yes), HighChol(0 = no, 1 = yes), and HeartDiseaseorAttack(0 = no, 1 = yes):         <|> Certainly! Based on the information you've provided, your name is Peter Jack, you're a 9-year-old female, your height is 170 centimeters, your weight is 49 kilograms, your BMI is [BMI calculated], you're a vegetarian, your annual income is 30,000, and you don't have any medical conditions or recent surgeries or procedures to report. Is that correct?</s>\n",
      "<|assistant|>\n",
      "No, I was mistaken. The given text in the previous message was actually an error on my part. I apologize. The information I was provided with is not related to personal information of a person. The text only describes a list of data elements required for a json object. Here's how you can summarize the json object for that:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"age\": 35,\n",
      "  \"bmi\": 24.5,\n",
      "  \"genHlth\": 4,\n",
      "  \"highBP\": 1,\n",
      "  \"diffWalk\": 0,\n",
      "  \"highChol\": 1,\n",
      "  \"heartDiseaseorAttack\": 0\n",
      "}\n",
      "```\n",
      "\n",
      "Note: I'm assuming that \"John Doe\" is an example provided or available to me. Adjust to actual personal information as necessary.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"age\": 35,\n",
      "  \"bmi\": 24.5,\n",
      "  \"genHlth\": 4,\n",
      "  \"highBP\": 1,\n",
      "  \"diffWalk\": 0,\n",
      "  \"highChol\": 1,\n",
      "  \"heartDiseaseorAttack\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "messages = [{\"role\": \"system\",\"content\": \"Your are a smart junior programmer.\"},\n",
    "            {\"role\": \"user\", \"content\": f'''Please summarize the following text related personal information as a json.\n",
    "            the json which only includes name, age, BMI, GenHlth(general health, scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor), \n",
    "            HighBP(0 = no, 1 = yes), DiffWalk(0 = no, 1 = yes), HighChol(0 = no, 1 = yes), and HeartDiseaseorAttack(0 = no, 1 = yes): {txt}'''}]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True)\n",
    "print(outputs[0][\"generated_text\"])\n",
    "print('--'*60)\n",
    "text = outputs[0][\"generated_text\"]\n",
    "start = text.find(\"{\")\n",
    "end = text.find(\"}\", start) + 1\n",
    "json_text = text[start:end]\n",
    "json_text = re.sub(r'(?<!\\\\\")//.*', '', json_text)\n",
    "json_data = json.loads(json_text)\n",
    "print(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcb8dc49-4627-4554-931e-d56fd5532ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'age': 35,\n",
       " 'bmi': 24.5,\n",
       " 'genHlth': 4,\n",
       " 'highBP': 1,\n",
       " 'diffWalk': 0,\n",
       " 'highChol': 1,\n",
       " 'heartDiseaseorAttack': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9aa24-e513-431d-907f-37a037b9a1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda39_v2)",
   "language": "python",
   "name": "conda39_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
